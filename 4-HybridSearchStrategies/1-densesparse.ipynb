{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d885e245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumanyadav/Desktop/Learn/Learn-RAG/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_classic.retrievers import EnsembleRetriever\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91ca4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Sample Documnets\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain is a framework for building applications with LLMs.\"),\n",
    "    Document(page_content=\"Pinecone is a vector database for sematic search\"),\n",
    "    Document(page_content=\"The Eiffel Tower is located in Paris.\"),\n",
    "    Document(page_content=\"Langchain can be used to develop agentic ai application.\"),\n",
    "    Document(page_content=\"langchain has many types of retrievers\")\n",
    "]\n",
    "\n",
    "# step 2 - Dense Retrieve (FAISS + HuggingFace)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "dense_vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "dense_retriever = dense_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6c0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sparse Retriever\n",
    "sparse_retriever = BM25Retriever.from_documents(docs)\n",
    "sparse_retriever.k = 3\n",
    "\n",
    "\n",
    "# step 4 - Combine with Ensamble Retriever\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[dense_retriever, sparse_retriever],\n",
    "    weight=[0.7,0.3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba9d6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x17ad10590>, search_kwargs={}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x17ad10c20>, k=3)], weights=[0.5, 0.5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72bc1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='7bea1eba-2e91-48f7-9b50-c7fee9af141d', metadata={}, page_content='Langchain can be used to develop agentic ai application.'), Document(id='9ac9455a-1210-473b-a58f-b93456a16e58', metadata={}, page_content='langchain has many types of retrievers'), Document(id='530d331e-c948-4a47-b2c4-6038e2ad4f1a', metadata={}, page_content='LangChain is a framework for building applications with LLMs.'), Document(id='064f7d73-d891-4a96-8ad2-5ebf94d2969a', metadata={}, page_content='Pinecone is a vector database for sematic search'), Document(metadata={}, page_content='The Eiffel Tower is located in Paris.')]\n",
      "\n",
      "Doument 1: Langchain can be used to develop agentic ai application.\n",
      "\n",
      "Doument 2: langchain has many types of retrievers\n",
      "\n",
      "Doument 3: LangChain is a framework for building applications with LLMs.\n",
      "\n",
      "Doument 4: Pinecone is a vector database for sematic search\n",
      "\n",
      "Doument 5: The Eiffel Tower is located in Paris.\n"
     ]
    }
   ],
   "source": [
    "# step 5 - Query and get result\n",
    "query = \"How can i build an application using LLMs?\"\n",
    "\n",
    "results = hybrid_retriever.invoke(query)\n",
    "print(results)\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nDoument {i+1}: {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f6d73",
   "metadata": {},
   "source": [
    "# RAG PIPELINE WITH HYBRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eefe669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Answere the question based on the following context'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Context:\\n{context}\\n\\nQuestion:\\n{question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6 - prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"Answere the question based on the following context\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"Context:\\n{context}\\n\\nQuestion:\\n{question}\")\n",
    "])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5256085",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_retrieval_chain' from 'langchain_classic.retrievers' (/Users/sumanyadav/Desktop/Learn/Learn-RAG/.venv/lib/python3.13/site-packages/langchain_classic/retrievers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_classic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretrievers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_retrieval_chain\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# step 7 - Initialize LLM\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'create_retrieval_chain' from 'langchain_classic.retrievers' (/Users/sumanyadav/Desktop/Learn/Learn-RAG/.venv/lib/python3.13/site-packages/langchain_classic/retrievers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_classic.retrievers import create_retrieval_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# step 7 - Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "# Step 8-  Create RAG chain using your hybrid retriever\n",
    "rag_chain = create_retrieval_chain(\n",
    "    llm=llm,\n",
    "    retriever=hybrid_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bdb5c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can build an application using LLMs by utilizing LangChain, which is a framework specifically designed for building applications with Large Language Models (LLMs).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDoument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "query = \"How can i build an application using LLMs?\"\n",
    "\n",
    "results = rag_chain.invoke(query)\n",
    "print(results)\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nDoument {i+1}: {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5773d45f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learn-RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
